import glob
import os
import time
from langchain_community.document_loaders import PyPDFLoader, UnstructuredWordDocumentLoader, TextLoader
from docling.document_converter import DocumentConverter
import warnings
from difflib import SequenceMatcher

FOLDER_PATH = "data"  # th∆∞ m·ª•c ch·ª©a d·ªØ li·ªáu c·ªßa b·∫°n

def calculate_similarity(text1, text2):
    """T√≠nh ƒë·ªô t∆∞∆°ng ƒë·ªìng gi·ªØa hai vƒÉn b·∫£n"""
    return SequenceMatcher(None, text1, text2).ratio()

def test_document_loaders():
    """H√†m test so s√°nh docling v√† loader truy·ªÅn th·ªëng cho t·∫•t c·∫£ file trong th∆∞ m·ª•c data"""
    # L·∫•y danh s√°ch t·∫•t c·∫£ c√°c file
    pdf_files = glob.glob(os.path.join(FOLDER_PATH, "*.pdf"))
    word_files = glob.glob(os.path.join(FOLDER_PATH, "*.docx*"))
    txt_files = glob.glob(os.path.join(FOLDER_PATH, "*.txt"))
    all_files = pdf_files + word_files + txt_files

    if not all_files:
        print("‚ùå Kh√¥ng t√¨m th·∫•y file n√†o trong th∆∞ m·ª•c data")
        return

    while True:
        print(f"\nüóÇÔ∏è Danh s√°ch file t√¨m th·∫•y ({len(all_files)} file):")
        for idx, file in enumerate(all_files, 1):
            print(f"{idx}. {os.path.basename(file)}")
        
        choice = input("\nCh·ªçn s·ªë th·ª© t·ª± file mu·ªën test (0 ƒë·ªÉ tho√°t): ")
        if choice == "0":
            break
            
        try:
            idx = int(choice) - 1
            if 0 <= idx < len(all_files):
                file_path = all_files[idx]
                test_single_file(file_path)
            else:
                print("‚ùå S·ªë th·ª© t·ª± kh√¥ng h·ª£p l·ªá!")
        except ValueError:
            print("‚ùå Vui l√≤ng nh·∫≠p s·ªë!")

def test_single_file(file_path):
    """Test m·ªôt file c·ª• th·ªÉ"""
    print(f"\n{'='*100}")
    print(f"üìÑ File: {os.path.basename(file_path)}")
    print(f"üìç ƒê∆∞·ªùng d·∫´n ƒë·∫ßy ƒë·ªß: {file_path}")
    print(f"üìä K√≠ch th∆∞·ªõc: {os.path.getsize(file_path)/1024:.2f} KB")
    print(f"{'='*100}\n")
    
    docling_text = ""
    traditional_text = ""
    docling_time = 0
    traditional_time = 0
    
    # Test docling
    print("üîç TH·ª¨ NGHI·ªÜM V·ªöI DOCLING:")
    start_time = time.time()
    try:
        converter = DocumentConverter()
        result = converter.convert(file_path)
        docling_text = result.document.export_to_markdown()
        docling_time = time.time() - start_time
        
        print(f"üìù ƒê·ªô d√†i vƒÉn b·∫£n: {len(docling_text)} k√Ω t·ª±")
        print(f"‚è±Ô∏è Th·ªùi gian x·ª≠ l√Ω: {docling_time:.2f} gi√¢y")
    except Exception as e:
        print(f"‚ùå L·ªói khi d√πng Docling: {str(e)}")
    
    # Test loader truy·ªÅn th·ªëng
    print("\nüîç TH·ª¨ NGHI·ªÜM V·ªöI LOADER TRUY·ªÄN TH·ªêNG:")
    start_time = time.time()
    try:
        file_extension = os.path.splitext(file_path)[1].lower()
        if file_extension == '.pdf':
            loader = PyPDFLoader(file_path)
        elif file_extension in ['.doc', '.docx']:
            loader = UnstructuredWordDocumentLoader(file_path)
        elif file_extension == '.txt':
            loader = TextLoader(file_path, encoding='utf-8')
        else:
            print(f"‚ùå Kh√¥ng h·ªó tr·ª£ ƒë·ªãnh d·∫°ng file: {file_extension}")
            return
            
        pages = loader.load_and_split()
        traditional_text = "\n\n".join(str(p.page_content) for p in pages)
        traditional_time = time.time() - start_time
        
        print(f"üìù ƒê·ªô d√†i vƒÉn b·∫£n: {len(traditional_text)} k√Ω t·ª±")
        print(f"üìÑ S·ªë trang/ƒëo·∫°n: {len(pages)}")
        print(f"‚è±Ô∏è Th·ªùi gian x·ª≠ l√Ω: {traditional_time:.2f} gi√¢y")
    except Exception as e:
        print(f"‚ùå L·ªói khi d√πng loader truy·ªÅn th·ªëng: {str(e)}")
    
    # So s√°nh k·∫øt qu·∫£
    print("\nüìä K·∫æT QU·∫¢ SO S√ÅNH:")
    print("-" * 50)
    if docling_text and traditional_text:
        similarity = calculate_similarity(docling_text, traditional_text)
        print(f"üîÑ ƒê·ªô t∆∞∆°ng ƒë·ªìng n·ªôi dung: {similarity:.2%}")
        print(f"‚ö° Ch√™nh l·ªách ƒë·ªô d√†i: {abs(len(docling_text) - len(traditional_text))} k√Ω t·ª±")
        print(f"‚è±Ô∏è Ch√™nh l·ªách th·ªùi gian: {abs(docling_time - traditional_time):.2f} gi√¢y")
        
        if similarity < 0.5:
            print("\n‚ö†Ô∏è C·∫£nh b√°o: ƒê·ªô t∆∞∆°ng ƒë·ªìng th·∫•p, c√≥ th·ªÉ c√≥ s·ª± kh√°c bi·ªát l·ªõn trong k·∫øt qu·∫£")
            
        print("\nüí° ƒê√°nh gi√°:")
        if docling_time < traditional_time:
            print("- Docling x·ª≠ l√Ω nhanh h∆°n")
        else:
            print("- Loader truy·ªÅn th·ªëng x·ª≠ l√Ω nhanh h∆°n")
            
        if len(docling_text) > len(traditional_text):
            print("- Docling tr√≠ch xu·∫•t ƒë∆∞·ª£c nhi·ªÅu n·ªôi dung h∆°n")
        else:
            print("- Loader truy·ªÅn th·ªëng tr√≠ch xu·∫•t ƒë∆∞·ª£c nhi·ªÅu n·ªôi dung h∆°n")
    else:
        print("‚ùå Kh√¥ng th·ªÉ so s√°nh do m·ªôt trong hai ph∆∞∆°ng ph√°p b·ªã l·ªói")

if __name__ == "__main__":
    warnings.filterwarnings("ignore")
    test_document_loaders()